---
layout:   post
title:    "技术总结 一"
subtitle: "技术总结"
date:     2019-02-14
author:   "NL"
header-img: "img/post-bg-2015.jpg"
tags:
    - 技术

---



## 技术总结

1. TCP与UDP协议

   > 1. 区别
   >
   >    1. 基于有连接与无连接
   >    2. 对系统资源的要求（TCP多）
   >    3. 流模式（TCP）与数据报模式（UDP）
   >    4. TCP保证顺序性、数据正确性（全双工）；UDP是不可靠信道
   >    5. TCP点对点的，UDP可以一对多，一对一，多对多通信
   >    6. TCP首部开销20字节；UDP首部开销小，8字节
   >
   > 2. TCP三次握手和四次握手
   >
   >    1. 报头：原端口号、目标端口号、序列号（发送数据位置）、确认应答号（下次收到的数据的序列号）、首都长度、保留、控制位（SYN、ACK、FIN）、窗口大小（接受缓存区大小）、校验和、紧急指针、选项；
   >
   >    2. 序列号的优点；1.保证报文有序到达；2.保证可靠性；3.保证效率；4.精准报告哪些报文收到，哪些报文重传
   >
   >    3. 三次握手
   >
   >       1. 一次握手：建立连接时，客户端发送SYN包到服务器，其中包含客户端的seq=x，并进入SYN_SENT状态，等待服务器确认（SYN=1，ACK=0，表示一个TCP连接请求数据报文；序号seq=x,表明传输数据时的第一个数据字节的序号是x）
   >       2. 二次握手：服务器收到请求后，必须确认客户的数据包。同时自己也发送一个SYN包，即SYN+ACK包，此时服务器进入SYN_RECV状态；（其中ACK=1，SYN=1，序号seq（服务器）=y， 确认号ack（服务器）=x（客户端）+1）
   >       3. 三次握手：客户端收到服务器的SYN+ACK包，向服务器发送一个序列号（seq=x+1），确认号ack（客户端）=y+1， 发送。客户端与服务器进入ESTAB_LISHED状态，完成三次握手。
   >
   >       4. 为什么是三次握手，而不是二次或者四次、五次
   >
   >          假设客户端请求建立连接，发送给服务器SYN包等待服务器确认，服务器收到确认后，如果是两次，假设客户端在第二次握手发送数据，数据从服务器发出，服务器认为连接已经建立，但是服务器在发送数据时，数据丢失服务器认为建立连接了，而客户端没收到确认，会进行重传，这样就会导致，服务器建立无用的多个连接，占用资源。
   >
   >    4. 四次握手
   >
   >       1. 一次握手：客户端发送一个FIN包，用来关闭客户端到服务器的数据发送，然后等待服务器确认，（终止位FIN=1，seq=u）
   >
   >       2. 二次握手：服务器收到FIN，发送一个ACK=1，ack=u+1，seq=v
   >
   >       3. 三次握手：关闭服务器到客户端的连接，发送FIN给客户端，FIN=1，ACK=1，seq=w，ack=u+1
   >
   >       4. 四次握手：客户端收到FIN后，并发回一个ACK报文确认，seq=w+1
   >
   >       5. 客户端发送FIN后，进入终止等待状态，服务器收到客户端连接释放报文后，就立即给客户端发送确认，服务器进入CLOSE_WAIT状态，此时TCP服务器通知高层应用程序，因而从客户端到服务器的连接就释放了。此时是“半关闭状态”，即客户端不可以发送给服务器，服务器可以发送给客户端。此时，如果服务器没有数据发送给客户端，其应用程序就通知TCP释放连接，然后发送给客户端释放报文，并等待确认。客户端发送确认后，进入TIME_WAIT状态，但是此时TCP连接还没释放，然后经过计时器设置2MSL后，才进入CLOSED状态。
   >
   >       6. 为什么是四次握手
   >
   >          双方关闭连接要经过双方同意，而且服务器收到客户端FIN包后，不能立即关闭，服务器还要看是否有数据还要传输。
   >
   > 3. 拥塞控制
   >
   >    1. 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载，以下是常用方法
   >    2. 慢开始算法（cwd<ssthresh(门限)防止出现网络拥堵问题）
   >    3. 拥塞避免算法（cwd>ssthresh ）：sstresh=出现拥塞时的发送窗口大小的一半，然后把拥塞窗口设为1
   >    4. 快重传算法：接受方收到失序的报文段就立即发出重复确认，而不是等到自己发送数据时
   >    5. 快恢复算法：如连续收到三个重复确认就应当重传对方未收到的报文段：ssthredh=ssthresh/1; cwd=ssthresh/2;
   >
   > 4. 流量控制
   >
   >    1. 所谓的流量控制就是让发送方的发送速率不要太快，让接收方来得及接受。利用滑动窗口机制可以很方便的在TCP连接上实现对发送方的流量控制。TCP的窗口单位是字节，不是报文段，发送方的发送窗口不能超过接收方给出的接收窗口的数值。

2. HTTP协议

   > 1. 超文本传输协议（无状态协议），处于应用层
   > 2. 基于TCP/IP通信协议来传递数据
   > 3. URI（统一资源**标识**符）、URL（统一资源**定位**器）
   > 4. URL各部分组成（协议部分、域名部分、端口部分、虚拟目录部分、文件名部分、锚部分、参数部分）
   > 5. 请求request
   >    1. 请求行 GET /index.php HTTP/1.1
   >    2. 请求头（Host、Accept、Accept-language、Accept-encoding、Referer、User-Agent(操作系统、CPU信息、浏览器类型、浏览器语言)）
   >    3. 空行
   >    4. 请求体（请求数据）
   > 6. 响应response
   >    1. 状态行 HTTP/1.1  200 OK
   >    2. 响应头（Content-type、Date、Content-Language、Content-Encoding）
   >    3. 空行
   >    4. 响应体（响应数据）
   >    5. 状态码：1xx：指示信息--表示请求已收到，继续处理；2xx：成功--表示请求已被成功接收、理解、接收；3xx：重定向--要完成请求必须进行下一步的操作；4xx：客户端错误--请求有语法错误或请求无法实现；5xx：服务端错误—服务器未能实现合法的请求；
   >    6. 502问题处理：网络问题、端口问题、服务器请求太多
   > 7. 工作原理
   >    1. 客户端连接web服务器：建立TCP套接字连接
   >    2. 发送HTTP请求
   >    3. 服务器接受请求并返回响应
   >    4. 释放连接（若connect：keepalive，连接会保持一段时间）
   >    5. 客户端浏览器解析HTML内容

3. session与cookie

   > 基于Http协议是无状态的，为了记住一些用户的浏览信息
   >
   > 1. cookie
   >    1. 概念：是浏览器保存在客户端的一段文本，用来保存用户在网站的必要信息（服务器告诉浏览器存储信息）
   >    2. 如何创建：服务器通过发送一个称为Set-Cookie的HTTP消息头来创建一个cookie，之后客户端请求服务器是，请求头中会有cookie字段来传输cookie信息。主要服务器返回的HTTP-only，来告知客户端，该cookie不能通过Javascript的document.cookie属性访问，以此防止XSS攻击
   >    3. 设置过期时间，没设置则会在会话结束后销毁
   >    4. 应用场景：1.判断用户是否登陆过网站。2.用户在同一个网站的不同页面选择不同的商品，可以将这些信息写入cookie，在最后付款时，从cookie中提取信息
   > 2. session
   >    1. session的作用和cookie差不多，但是他是存储在服务器上，对于cookie来说。比较安全。
   >    2. 一般会使用cookie来管理session，若禁用cookie，可以把session放到参数中，一样可以实现。或者URL重写
   >    3. 会话结束后，客户端session自动失效，不会使服务器的session失效
   >    4. 应用场景：除了纯静态页面，都会用到session

4. Nginx与php-fpm

   > 1. Nginx是一个高性能的HTTP和反向代理服务器，也是IMAP/POP3/SMTP服务器
   >
   >    1. 模块：从结构上分为核心模块、基础模块和第三方模块
   >
   >       1. 核心模块：HTTP模块、EVENT模块和MAIL模块
   >       2. 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块
   >       3. 第三方模块：HTTP Upstream Request Hash模块、Notice模块、HTTP Access Key模块
   >
   >    2. 如何工作
   >
   >       1. master进程：管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能，充当整个进程组与用户交互接口，同时对进程进行监护。他不需要处理网络事件，不负责业务的执行，
   >       2. worker进程：处理基本网络事件，worker进程数量基本设置为与CPU核数相等（多了会有进程上下文切换消耗）；以下是处理过程：首先，每个worker进程都是从master进程fork过来的，在master进程中，先建立号需要listen的socket（listenfd）后，然后在fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理连接，所有worker进程在注册listenfd读事件前抢accept_mutex锁，抢到互斥锁的进程注册listenfd读事件，在读事件里调用accept接受该连接。连接之后，就开始读取请求，解析请求，处理请求，产生数据后，在返回给客户端，最后才断开连接。
   >       3. 缓存加载器进程：负责将磁盘高速缓存加载到内存中，这个进程在启动时运行后随即退出
   >       4. 缓存管理器进程：负责整理磁盘缓存的数据保证其不越界，间歇性运行
   >
   >    3. 高性能—多进程IO多路复用（epoll）模型
   >
   >       1. nginx采用多进程模型：首先，对于每个worker进程来说，独立进程，不需要加锁。
   >
   >       2. 多路复用模型epoll
   >
   >          epoll与select的区别
   >
   >          select：
   >
   >          1. 每次调用select,都需要把fd集合从用户态拷贝到内核态
   >          2. 同时每次调用select都需要在内核遍历传递进来的所有fd集合
   >          3. select支持的文件描述符数量太小
   >
   >          epoll
   >
   >          1. 每次注册的时间到epoll句柄中，会把所有的fd拷贝进内核，而不是在epoll_wait时重复拷贝；epoll保证每个fd只拷贝一次
   >          2. epoll_ctl为每个fd指定一个回调函数，当设备就绪，就会调用回调函数。epoll_wait的工作就是在这个就绪链表中查看没有就绪的额fd
   >          3. epoll没有限制，他支持的FD上限时最大可以打开的文件数目
   >
   >          总结：
   >
   >          1. select与poll实现需要自己不断轮询所有fd集合，直到设备就绪；而epoll也需要轮询就绪链表，而不是所有的fd集合，而只是就绪的fd
   >
   > 2. php-fpm
   >
   >    1. CGI协议：为了解决不同的语言解释器与webserver的通信。
   >
   >       1. webserver每收到一个请求。都会去fork一个cgi进程，请求结束在kill掉进程。
   >       2. 于是，出现了fast-cgi协议，fast-cgi每次处理完请求后，不会kill掉进程，而是保留进程，使这个进程处理更多的请求
   >
   >    2. php-fpm
   >
   >       1. php-fastcgi Progress Manager，php-fpm是Fastcgi的实现，并提供进程管理的功能
   >
   >       2. 进程包含master和worker进程，master进程监听端口，接收来自Web Server的请求，而worker进程内部都嵌入一个php解释器，是php代码真正执行的地方
   >
   >       3. Nginx通过反向代理，将动态请求转向后端
   >
   >       4. 配置
   >
   >          ```nginx
   >          server {
   >              listen 80; #监听80端口，接收http请求
   >              server_name www.example.com; #就是网站地址
   >              root /usr/local/etc/nginx/www/code; #准备存放代码工程的路径
   >              location / {
   >                  index index.php; #跳转到www.example.com/index.php
   >                  autoindex on;
   >              }
   >              location ~\.php$ {
   >              	include /usr/local/etc/nginx/fastcgi.conf;#加载nginx的fastcgi模块
   >              	fastcgi_intercept_errors on; 
   >             		fastcgi_pass 127.0.0.1:9000; #nginx fastcgi进程监听的IP地址和端口
   >          	}
   >          }
   >          ```
   >
   >       5. nginx与php-fpm完整流程
   >
   >          ```php
   >          www.example.com
   >          	|
   >            Nginx
   >            	|
   >          路由到www.example.com/index.php
   >          	|
   >          加载nginx的fastcgi模块
   >          	|
   >          fastcgi监听127.0.0.1:9000地址
   >          	|
   >          www.example.com/index.php请求到达127.0.0.1:9000
   >          	|
   >          php-fpm监听127.0.0.1:9000
   >          	|
   >          php-fpm接收到请求，启用worker进程处理请求
   >          	|
   >          php-fpm处理完请求，返回给nginx
   >          	|
   >          nginx将结果通过http返回给浏览器
   >          ```

5. redis

   > 1. redis是支持key-value等多种数据结构的存储系统，可用于缓存、事件发布或订阅、高速队列等场景
   >
   > 2. 数据结构
   >
   >    1. string（字符串）：键值最大存储512MB
   >    2. hash（哈希）：是一个键值对的集合，是一个string类型的field的value的映射表
   >    3. list（列表）：它按插入顺序排序
   >    4. Set（无序集合）：不可重复；微博好友与粉丝记录
   >    5. zset（有序集合）：string类型的有序集合，不可重复，每个元素与都有一个分数，根据分数对元素进行升序排序，如果多个元素有相同的分数，则以字典序进行升序排序；
   >
   > 3. 应用场景
   >
   >    1. 会话缓存（string）
   >    2. 消息队列
   >    3. 活动排行榜或计数（string）
   >    4. 发布、订阅消息
   >    5. 商品列表、评论列表（list）
   >
   > 4. redis服务相关的命令
   >
   >    1. select 选择数据库
   >    2. quit 退出连接
   >    3. info 获得服务的信息与统计
   >    4. monitor 实时监控
   >    5. config get 获得服务配置
   >    6. flushdb 删除当前选择的数据库中key
   >    7. flushall 删除所有数据库中的key
   >
   > 5. 发布与订阅
   >
   > 6. 持久化
   >
   >    1. 内存快照
   >
   >       1. 将内存中的数据以快照方式写入二进制文件中，默认文件名：dump.rdb
   >       2. Save seconds changes配置：s秒中若有c个key更改，就进行快照操作
   >       3. save命令在主线程中保存内存快照，内存快照每次都把内存数据完整地写入硬盘
   >       4. 数据量大，写入操作频繁。
   >
   >    2. 日志追加
   >
   >       1. 把增加、更改数据的命令通过write追加到文件尾部默认文件：appendonly.aof。Redis重启后读取文件中的所有命令执行一边，从而把数据写入内存
   >
   >          ```shell
   >          appendonly yes #开启日志追加持久化存储方式
   >          appendonly always #收到写命令就立即写入磁盘
   >          appendonly everysec # 每秒写入一次
   >          appendonly on #依赖os
   >          ```
   >
   > 7. 与Memecached的区别
   >
   >    1. redis支持的数据结构更多，而memecached只支持简单的数据类型，string
   >    2. redis支持数据的备份，即master-slave模式的数据备份
   >    3. redis支持数据的持久化，而memecached只存储在内存中
   >    4. redis的速度比memecached快很多
   >    5. Memecached是多线程，非阻塞IO复用模型；redis使用单线程的IO复用模型
   >
   > 8. 优点
   >
   >    1. 速度快。类似Hashmap，查找和操作的时间复杂度为O(1)
   >    2. 支持丰富的数据类型
   >    3. 支持事务
   >    4. 丰富的特性：可用于缓存，消息，将key设置过期时间，过期自动删除
   >
   > 9. 相关连接：https://segmentfault.com/a/1190000014488045
   >
   > 10. redis回收进程使用LRU算法（最近最久未使用算法）

6. 消息队列

   > 1. 一种进程间通信或同一进程的不同线程间的通信方式
   >
   > 2. 特点
   >
   >    1. 异步：异步通知消费者
   >    2. 解耦：不同服务之间通过消息队列通行，不用关系彼此
   >    3. 广播：广播通知下游系统
   >    4. 流量削峰与流控：数据库的处理有限制，等系统有处理的能力，再去处理
   >
   > 3. 缺点
   >
   >    1. 系统可用性降低
   >    2. 系统复杂度提高
   >    3. 一致性问题
   >
   > 4. | 特性                    | ActiveMQ                                                     | RabbitMQ                                                     | RocketMQ                                                     |                            Kafka                             |
   >    | ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | :----------------------------------------------------------: |
   >    | 单机吞吐量              | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级                | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级                | 10万级，RocketMQ也是可以支撑高吞吐的一种MQ                   | 10万级别，这是kafka最大的优点，就是吞吐量高。 一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
   >    | topic数量对吞吐量的影响 |                                                              |                                                              | topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降 这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic | topic从几十个到几百个的时候，吞吐量会大幅度下降 所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源 |
   >    | 时效性                  | ms级                                                         | 微秒级，这是rabbitmq的一大特点，延迟是最低的                 | ms级                                                         |                        延迟在ms级以内                        |
   >    | 可用性                  | 高，基于主从架构实现高可用性                                 | 高，基于主从架构实现高可用性                                 | 非常高，分布式架构                                           | 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
   >    | 消息可靠性              | 有较低的概率丢失数据                                         |                                                              | 经过参数优化配置，可以做到0丢失                              |             经过参数优化配置，消息可以做到0丢失              |
   >    | 功能支持                | MQ领域的功能极其完备                                         | 基于erlang开发，所以并发能力很强，性能极其好，延时很低       | MQ功能较为完善，还是分布式的，扩展性好                       | 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 |
   >    | 优劣势总结              | 非常成熟，功能强大，在业内大量的公司以及项目中都有应用 偶尔会有较低概率丢失消息 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用 | erlang语言开发，性能极其好，延时很低； 吞吐量到万级，MQ功能比较完备 而且开源提供的管理界面非常棒，用起来很好用 社区相对比较活跃，几乎每个月都发布几个版本分 在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 | 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的 | kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集 |
   >
   >    模式：**单机模式、普通集群模式、镜像集群模式**

7. Mysql

   > 1. 数据库完整性约束：
   >
   >    1. 实体完整（主键不能为空或重复值）
   >    2. 参照完整（两张表数据一致）
   >    3. 用户自定义完整：非空约束、唯一约束、检查约束、主键约束、外键约束
   >
   > 2. 事务
   >
   >    1. 特性
   >       1. 原子性：完成或失败
   >       2. 一致性：在事务开始之前和事物结束之后，数据库的完整性约束没有被破坏
   >       3. 隔离性：事务在隔离的状态下执行
   >       4. 持久性：在事务完成以后，数据所作的更改便持久保存在数据库中
   >    2. 实现方式：都是通过事务日志实现
   >       1. 隔离性：通过锁来实现
   >       2. 一致性和持久性：通过redo log来实现
   >       3. 原子性：通过undo log来实现
   >    3. 隔离级别
   >       1. 问题
   >          1. 脏读：一个事务读到另一个事务未提交的数据
   >          2. 不可重复读：一个事务读到另一个事务提交的事务
   >          3. 幻读：事务A读到事务B已提交的新增数据
   >       2. 类型
   >          1. 读未提交：（脏读）
   >          2. 读提交：（不可重复读）
   >          3. 可重复读：间隙锁解决幻读问题（可能发生幻读）多版本控制（MVCC）解决不可重复读问题
   >          4. 串行：解决了幻读
   >       3. 查看隔离级别：SELECT @@tx_isolation；切换隔离级别命令：set session transaction isolation level 隔离级别名
   >    4. 事务执行
   >       1. start transaction
   >       2. 记录A=1到undo log
   >       3. update A=3
   >       4. 记录A=3到redo log
   >       5. 记录到B=2到undo log
   >       6. update B=4
   >       7. 记录B=4到redo log
   >       8. 将redo log刷新到磁盘
   >       9. commit
   >       10. undo log清除
   >
   > 3. 视图
   >
   >    1. 虚拟的表
   >    2. 视图不能被索引，也不能有触发器
   >    3. 不能更新
   >
   > 4. 常用命令
   >
   >    1. drop：直接删除掉表
   >    2. truncate：删除表中所有数据，自增ID设置为1
   >    3. delete：删除表中的数据
   >    4. show processlist:查看发起的线程
   >
   > 5. 索引
   >
   >    1. 常用数据结构：B树及其变种B+树、Hash索引
   >    2. 优点
   >       1. 唯一索引，保证数据的唯一性
   >       2. 加快检索速度
   >       3. 可以加速表与表的连接
   >       4. 分组和排序时，减少查询速度
   >    3. 缺点
   >       1. 创建索引与维护索引耗时，随着数据量增加而增加
   >       2. 索引占用物理空间
   >       3. 对数据进行修改、删除和增加时，索引要动态维护
   >    4. 建立索引
   >       1. text、image、bit数据类型不应该增加索引
   >       2. 对于数据只有很少的数据值时不应该增加索引
   >       3. 很少使用的列，不应该增加索引
   >    5. 索引失效
   >       1. like以%开始
   >       2. 条件是or
   >       3. 内部函数
   >       4. is null不会用，is not null会用
   >    6. B树
   >       1. 特征
   >          1. 定义任意的非叶子结点最多只有M个儿子，且M>2
   >          2. 根结点的至少儿子数为2
   >          3. 除根节点以外的非叶子结点的儿子数[M/2, M]，向上取整
   >          4. 非叶子结点的关键字个数为儿子数-1
   >          5. 所有叶子结点位于同一层
   >          6. k个关键字把结点拆成k+1端，分别指向k+1个儿子
   >       2. 特性
   >          1. 关键字集合分布在整颗树中
   >          2. 任何一个关键字出现且出现在一个结点
   >          3. 搜索有可能在非叶子结点
   >          4. 其搜索性能等价于在关键字内做一次二分查找
   >    7. B+树
   >       1. 特征
   >          1. 有n颗子树的非叶子结点中含有n个关键字，这些关键字不保存数据，只用来索引，所有数据都保存在叶子结点
   >          2. 所有的叶子结点中包含了全部关键字的信息，即指向含这些关键字记录的指针，且叶子结点本身关键字的大小自小而大顺序连接
   >          3. 所有非叶子结点可以看成索引部分，结点中仅含其子树中的最大关键字
   >          4. 通常在b+树有两个头指针，一个指向根结点，一个指向最小的叶子结点
   >          5. 同一个数字会在不同节点重复出现，根结点的最大元素就是B+树的最大元素
   >       2. 优点
   >          1. 查询性能稳定
   >          2. 区间查询更快
   >          3. IO次数减少，数据页只存储key，用来索引，整个树显得矮胖
   >    8. Hash索引与B+树优缺点
   >       1. hash索引，等值查询效率比较高，但不能排序、范围查询
   >       2. 数据有序，范围查询
   >    9. innodb与myslam索引的区别
   >       1. 主索引的区别：innodb的数据文件本身就是索引文件；myslam的索引与数据是分开的
   >       2. 辅助索引区别：InnoDB的辅助索引data域存储相应记录主键而不是地址；而myslam辅助索引与主索引无区别
   >
   > 6. 数据库的主从复制
   >
   >    1. 异步复制：容易造成数据不一致，slave数据库两个线程，一个线程去读主库binlog，写到自己的中继日志，一个线程解析日志，执行sql；master一个线程去传递binlog日志
   >
   >    2. 半同步复制：介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立即返回给客户端，而是等到至少一个从库接收到并写到realy log中才返回给客户端。相对于异步复制，半同步复制提高了数据库的安全性，同时也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用
   >
   >    3. 全同步复制：指当主库执行完一个事务，等到所有从库都执行完该事务才将结果返回给客户端。因为需要等待所有从库都执行完下能返回，所以全同步复制的性能必然会受到影响，需要有超时时间。
   >

8. 操作系统

   > 1. socket编程
   >
   >    1. Unix domain socket与tcp socket
   >
   >       1. domain socket只能本机通信，进程间通信，效率、吞吐量要比tcp socket高。tcp socket网络通信
   >
   >       2. Ip socket利用主机的传输层(tcp)，可以用于同一台主机上不同进程间的通信，也可以用于网络上不同主机间的通信。
   >
   >       3. 配置php-fpm与Nginx交互的socket:
   >
   >          ```nginx
   >          fastcgi_pass 127.0.0.1:9000
   >          fastcgi_pass unix:/var/run/php-fpm/php-fpm.sock
   >          ```
   >
   >    2. TCP与UDP编程
   >
   >       1. TCP
   >          1. 服务端
   >             1. 创建一个socket，用函数socket()； 
   >             2. 绑定IP地址、端口等信息到socket上，用函数bind(); 
   >             3. 开启监听，用函数listen()； 
   >             4. 接收客户端上来的连接，用函数accept()； 
   >             5. 收发数据，用函数send()和recv()，或者read()和write(); 
   >             6. 关闭网络连接； 
   >             7. 关闭监听；
   >          2. 客户端
   >             1. 创建一个socket
   >             2. 设置连接的IP和端口，bind绑定
   >             3. 连接服务器，connent()
   >             4. 收发数据，用函数send()和recv()，或者read()和write(); 
   >             5. 关闭网络连接
   >       2. UDP
   >          1. 服务端
   >             1. 创建一个socket，用函数socket()
   >             2. 绑定IP地址、端口等信息到socket上，用函数bind(); 
   >             3. 循环接收数据，用函数recvfrom(); 
   >             4. 循环发送数据，用函数sendto(); 
   >             5. 关闭网络连接；
   >          2. 客户端
   >             1. 创建一个socket，用函数socket()； 
   >             2. 设置对方的IP地址和端口等属性;，bind绑定
   >             3. 发送数据，用函数sendto(); 
   >             4. 接收数据，用函数recvfrom()
   >             5. 关闭网络连接
   >
   > 2. 进程与线程
   >
   >    1. 进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。
   >       1. 进程间通信：管道、系统**IPC**（包括消息队列、信号量、共享存储）、**SOCKET**
   >       2. 进程状态：就绪状态、运行状态、阻塞状态
   >       3. 调度算法：FCFS(先来先服务)，优先级，时间片轮转，多级反馈
   >    2. 通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源。在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位。由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统内多个程序间并发执行的程度。**线程是分配CPU资源的最小单位，单CPU多线程是时间轮片的切换，多CPU可以真正的做到多CPU同时工作**。
   >    3. **线程与进程的区别归纳：**
   >       1. **地址空间和其它资源**：进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见
   >       2. **通信：**进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性
   >       3. **调度和切换**：线程上下文切换比进程上下文切换要快得多。
   >       4. 在多线程OS中，进程不是一个可执行的实体。
   >
   > 3. 死锁
   >
   >    1. 产生死锁的条件
   >       1. 互斥条件：一个资源每次只能被一个进程使用
   >       2. 占有并等待条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
   >       3. 非抢占:进程已获得的资源，在末使用完之前，不能强行剥夺。
   >       4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
   >
   > 4. 抖动
   >
   >    1. 在请求分页存储管理中，从主存（DRAM）中刚刚换出（Swap Out）某一页面后（换出到Disk），根据请求马上又换入（Swap In）该页，这种反复换出换入的现象，称为系统颠簸，也叫系统抖动。产生该现象的主要原因是置换算法选择不当。
   >    2. 多道程序度过高，导致平均驻留集过小。
   >
   > 5. 常见页面置换算法
   >
   >    1. 先进先出FIFO
   >    2. 最近最久置换算法：LRU是堆栈类的算法，需要寄存器和栈的硬件支持
   >    3. **最佳置换算法（OPT）**（理想置换算法）
   >
   > 6. 内存管理中的分页和分段
   >
   >    1. 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）
   >    2. 页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）

9. 

10. 

11. 

    >


